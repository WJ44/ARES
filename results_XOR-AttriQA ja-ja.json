[[{"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.5_ja_ja.tsv", "ARES_Prediction": 0.18666666666666665, "ARES_Confidence_Interval": [0.079, 0.295], "Number_of_Examples_in_Evaluation_Set": 72, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.583, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.525_ja_ja.tsv", "ARES_Prediction": 0.1995774647887324, "ARES_Confidence_Interval": [0.094, 0.305], "Number_of_Examples_in_Evaluation_Set": 71, "Ground_Truth_Performance": 0.521, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.592, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.55_ja_ja.tsv", "ARES_Prediction": 0.14323943661971827, "ARES_Confidence_Interval": [0.027, 0.26], "Number_of_Examples_in_Evaluation_Set": 71, "Ground_Truth_Performance": 0.549, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.676, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.575_ja_ja.tsv", "ARES_Prediction": 0.10098591549295777, "ARES_Confidence_Interval": [-0.022, 0.224], "Number_of_Examples_in_Evaluation_Set": 71, "Ground_Truth_Performance": 0.577, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.746, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.6_ja_ja.tsv", "ARES_Prediction": 0.2559154929577465, "ARES_Confidence_Interval": [0.165, 0.347], "Number_of_Examples_in_Evaluation_Set": 71, "Ground_Truth_Performance": 0.606, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.62, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.625_ja_ja.tsv", "ARES_Prediction": 0.2283333333333334, "ARES_Confidence_Interval": [0.13, 0.327], "Number_of_Examples_in_Evaluation_Set": 72, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.667, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.65_ja_ja.tsv", "ARES_Prediction": 0.1854929577464789, "ARES_Confidence_Interval": [0.077, 0.294], "Number_of_Examples_in_Evaluation_Set": 71, "Ground_Truth_Performance": 0.648, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.732, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.675_ja_ja.tsv", "ARES_Prediction": 0.1995774647887324, "ARES_Confidence_Interval": [0.094, 0.305], "Number_of_Examples_in_Evaluation_Set": 71, "Ground_Truth_Performance": 0.676, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.746, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.7_ja_ja.tsv", "ARES_Prediction": 0.1995774647887324, "ARES_Confidence_Interval": [0.094, 0.305], "Number_of_Examples_in_Evaluation_Set": 71, "Ground_Truth_Performance": 0.704, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.775, "Annotated_Examples_used_for_PPI": 100}]]