[[{"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.5_en_ja.tsv", "ARES_Prediction": 0.18888888888888888, "ARES_Confidence_Interval": [0.073, 0.304], "Number_of_Examples_in_Evaluation_Set": 72, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.611, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.525_en_ja.tsv", "ARES_Prediction": 0.21549295774647892, "ARES_Confidence_Interval": [0.105, 0.326], "Number_of_Examples_in_Evaluation_Set": 71, "Ground_Truth_Performance": 0.521, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.606, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.55_en_ja.tsv", "ARES_Prediction": 0.20140845070422542, "ARES_Confidence_Interval": [0.088, 0.315], "Number_of_Examples_in_Evaluation_Set": 71, "Ground_Truth_Performance": 0.549, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.648, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.575_en_ja.tsv", "ARES_Prediction": 0.11690140845070429, "ARES_Confidence_Interval": [-0.01, 0.244], "Number_of_Examples_in_Evaluation_Set": 71, "Ground_Truth_Performance": 0.577, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.761, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.6_en_ja.tsv", "ARES_Prediction": 0.27183098591549304, "ARES_Confidence_Interval": [0.174, 0.37], "Number_of_Examples_in_Evaluation_Set": 71, "Ground_Truth_Performance": 0.606, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.634, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.625_en_ja.tsv", "ARES_Prediction": 0.2583333333333334, "ARES_Confidence_Interval": [0.157, 0.359], "Number_of_Examples_in_Evaluation_Set": 72, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.667, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.65_en_ja.tsv", "ARES_Prediction": 0.20140845070422542, "ARES_Confidence_Interval": [0.088, 0.315], "Number_of_Examples_in_Evaluation_Set": 71, "Ground_Truth_Performance": 0.648, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.746, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.675_en_ja.tsv", "ARES_Prediction": 0.22957746478873242, "ARES_Confidence_Interval": [0.122, 0.337], "Number_of_Examples_in_Evaluation_Set": 71, "Ground_Truth_Performance": 0.676, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.746, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.7_en_ja.tsv", "ARES_Prediction": 0.24366197183098592, "ARES_Confidence_Interval": [0.139, 0.348], "Number_of_Examples_in_Evaluation_Set": 71, "Ground_Truth_Performance": 0.704, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.761, "Annotated_Examples_used_for_PPI": 100}]]