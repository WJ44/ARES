[[{"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_test_ratio_0.5_de_en.tsv", "ARES_Prediction": 0.48387154262902765, "ARES_Confidence_Interval": [0.423, 0.545], "Number_of_Examples_in_Evaluation_Set": 1002, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.883, "Annotated_Examples_used_for_PPI": 112}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_test_ratio_0.525_de_en.tsv", "ARES_Prediction": 0.4995320455226116, "ARES_Confidence_Interval": [0.438, 0.561], "Number_of_Examples_in_Evaluation_Set": 954, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.885, "Annotated_Examples_used_for_PPI": 112}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_test_ratio_0.55_de_en.tsv", "ARES_Prediction": 0.5245879120879121, "ARES_Confidence_Interval": [0.463, 0.586], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.895, "Annotated_Examples_used_for_PPI": 112}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_test_ratio_0.575_de_en.tsv", "ARES_Prediction": 0.5422851402329014, "ARES_Confidence_Interval": [0.48, 0.604], "Number_of_Examples_in_Evaluation_Set": 871, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.876, "Annotated_Examples_used_for_PPI": 112}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_test_ratio_0.6_de_en.tsv", "ARES_Prediction": 0.5609174508126604, "ARES_Confidence_Interval": [0.499, 0.623], "Number_of_Examples_in_Evaluation_Set": 835, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.893, "Annotated_Examples_used_for_PPI": 112}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_test_ratio_0.625_de_en.tsv", "ARES_Prediction": 0.5611177991795969, "ARES_Confidence_Interval": [0.498, 0.624], "Number_of_Examples_in_Evaluation_Set": 801, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.864, "Annotated_Examples_used_for_PPI": 112}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_test_ratio_0.65_de_en.tsv", "ARES_Prediction": 0.5683441558441559, "ARES_Confidence_Interval": [0.505, 0.631], "Number_of_Examples_in_Evaluation_Set": 770, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.862, "Annotated_Examples_used_for_PPI": 112}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_test_ratio_0.675_de_en.tsv", "ARES_Prediction": 0.629211590296496, "ARES_Confidence_Interval": [0.566, 0.692], "Number_of_Examples_in_Evaluation_Set": 742, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.9, "Annotated_Examples_used_for_PPI": 112}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_test_ratio_0.7_de_en.tsv", "ARES_Prediction": 0.6141983016983017, "ARES_Confidence_Interval": [0.551, 0.678], "Number_of_Examples_in_Evaluation_Set": 715, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.834, "Annotated_Examples_used_for_PPI": 112}], [{"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_test_ratio_0.5_de_en.tsv", "ARES_Prediction": 0.4821963216424294, "ARES_Confidence_Interval": [0.439, 0.525], "Number_of_Examples_in_Evaluation_Set": 1002, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.975, "Annotated_Examples_used_for_PPI": 112}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_test_ratio_0.525_de_en.tsv", "ARES_Prediction": 0.5119983528002395, "ARES_Confidence_Interval": [0.468, 0.556], "Number_of_Examples_in_Evaluation_Set": 954, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.972, "Annotated_Examples_used_for_PPI": 112}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_test_ratio_0.55_de_en.tsv", "ARES_Prediction": 0.5292582417582418, "ARES_Confidence_Interval": [0.485, 0.573], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.977, "Annotated_Examples_used_for_PPI": 112}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_test_ratio_0.575_de_en.tsv", "ARES_Prediction": 0.5495633098245039, "ARES_Confidence_Interval": [0.505, 0.594], "Number_of_Examples_in_Evaluation_Set": 871, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.987, "Annotated_Examples_used_for_PPI": 112}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_test_ratio_0.6_de_en.tsv", "ARES_Prediction": 0.5792023096663815, "ARES_Confidence_Interval": [0.535, 0.624], "Number_of_Examples_in_Evaluation_Set": 835, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.98, "Annotated_Examples_used_for_PPI": 112}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_test_ratio_0.625_de_en.tsv", "ARES_Prediction": 0.6049246477617264, "ARES_Confidence_Interval": [0.56, 0.65], "Number_of_Examples_in_Evaluation_Set": 801, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.979, "Annotated_Examples_used_for_PPI": 112}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_test_ratio_0.65_de_en.tsv", "ARES_Prediction": 0.6238636363636364, "ARES_Confidence_Interval": [0.579, 0.669], "Number_of_Examples_in_Evaluation_Set": 770, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.979, "Annotated_Examples_used_for_PPI": 112}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_test_ratio_0.675_de_en.tsv", "ARES_Prediction": 0.641677897574124, "ARES_Confidence_Interval": [0.596, 0.687], "Number_of_Examples_in_Evaluation_Set": 742, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.977, "Annotated_Examples_used_for_PPI": 112}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_test_ratio_0.7_de_en.tsv", "ARES_Prediction": 0.679507992007992, "ARES_Confidence_Interval": [0.635, 0.724], "Number_of_Examples_in_Evaluation_Set": 715, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.975, "Annotated_Examples_used_for_PPI": 112}], [{"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_test_ratio_0.5_de_en.tsv", "ARES_Prediction": 0.4778656971770744, "ARES_Confidence_Interval": [0.385, 0.571], "Number_of_Examples_in_Evaluation_Set": 1002, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.726, "Annotated_Examples_used_for_PPI": 112}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_test_ratio_0.525_de_en.tsv", "ARES_Prediction": 0.48259209344115006, "ARES_Confidence_Interval": [0.389, 0.576], "Number_of_Examples_in_Evaluation_Set": 954, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.711, "Annotated_Examples_used_for_PPI": 112}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_test_ratio_0.55_de_en.tsv", "ARES_Prediction": 0.5019230769230769, "ARES_Confidence_Interval": [0.408, 0.596], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.722, "Annotated_Examples_used_for_PPI": 112}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_test_ratio_0.575_de_en.tsv", "ARES_Prediction": 0.51789814662949, "ARES_Confidence_Interval": [0.424, 0.612], "Number_of_Examples_in_Evaluation_Set": 871, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.703, "Annotated_Examples_used_for_PPI": 112}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_test_ratio_0.6_de_en.tsv", "ARES_Prediction": 0.5461291702309666, "ARES_Confidence_Interval": [0.452, 0.641], "Number_of_Examples_in_Evaluation_Set": 835, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.699, "Annotated_Examples_used_for_PPI": 112}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_test_ratio_0.625_de_en.tsv", "ARES_Prediction": 0.5335072231139647, "ARES_Confidence_Interval": [0.439, 0.628], "Number_of_Examples_in_Evaluation_Set": 801, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.664, "Annotated_Examples_used_for_PPI": 112}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_test_ratio_0.65_de_en.tsv", "ARES_Prediction": 0.5496753246753247, "ARES_Confidence_Interval": [0.455, 0.645], "Number_of_Examples_in_Evaluation_Set": 770, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.653, "Annotated_Examples_used_for_PPI": 112}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_test_ratio_0.675_de_en.tsv", "ARES_Prediction": 0.6074797843665768, "ARES_Confidence_Interval": [0.512, 0.703], "Number_of_Examples_in_Evaluation_Set": 742, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.712, "Annotated_Examples_used_for_PPI": 112}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_test_ratio_0.7_de_en.tsv", "ARES_Prediction": 0.5768481518481519, "ARES_Confidence_Interval": [0.481, 0.672], "Number_of_Examples_in_Evaluation_Set": 715, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.627, "Annotated_Examples_used_for_PPI": 112}]]