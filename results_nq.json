[[{"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "datasets/eval_datasets/nq/nq_ratio_0.5.tsv", "ARES_Prediction": 0.5576793567031034, "ARES_Confidence_Interval": [0.498, 0.618], "Number_of_Examples_in_Evaluation_Set": 5306, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.745, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "datasets/eval_datasets/nq/nq_ratio_0.525.tsv", "ARES_Prediction": 0.5697651560129297, "ARES_Confidence_Interval": [0.51, 0.63], "Number_of_Examples_in_Evaluation_Set": 5053, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.745, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "datasets/eval_datasets/nq/nq_ratio_0.55.tsv", "ARES_Prediction": 0.5823049277766259, "ARES_Confidence_Interval": [0.522, 0.642], "Number_of_Examples_in_Evaluation_Set": 4823, "Ground_Truth_Performance": 0.55, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.744, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "datasets/eval_datasets/nq/nq_ratio_0.575.tsv", "ARES_Prediction": 0.593140400317942, "ARES_Confidence_Interval": [0.533, 0.653], "Number_of_Examples_in_Evaluation_Set": 4613, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.745, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "datasets/eval_datasets/nq/nq_ratio_0.6.tsv", "ARES_Prediction": 0.6059707456834804, "ARES_Confidence_Interval": [0.546, 0.666], "Number_of_Examples_in_Evaluation_Set": 4421, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.744, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "datasets/eval_datasets/nq/nq_ratio_0.625.tsv", "ARES_Prediction": 0.6187056236255105, "ARES_Confidence_Interval": [0.558, 0.679], "Number_of_Examples_in_Evaluation_Set": 4244, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.744, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "datasets/eval_datasets/nq/nq_ratio_0.65.tsv", "ARES_Prediction": 0.6323115249530344, "ARES_Confidence_Interval": [0.572, 0.693], "Number_of_Examples_in_Evaluation_Set": 4081, "Ground_Truth_Performance": 0.65, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.742, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "datasets/eval_datasets/nq/nq_ratio_0.675.tsv", "ARES_Prediction": 0.6460305343511451, "ARES_Confidence_Interval": [0.586, 0.706], "Number_of_Examples_in_Evaluation_Set": 3930, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.74, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "datasets/eval_datasets/nq/nq_ratio_0.7.tsv", "ARES_Prediction": 0.6572647317502199, "ARES_Confidence_Interval": [0.597, 0.718], "Number_of_Examples_in_Evaluation_Set": 3790, "Ground_Truth_Performance": 0.7, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.741, "Annotated_Examples_used_for_PPI": 300}], [{"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "datasets/eval_datasets/nq/nq_ratio_0.5.tsv", "ARES_Prediction": 0.5062080663399925, "ARES_Confidence_Interval": [0.489, 0.524], "Number_of_Examples_in_Evaluation_Set": 5306, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.983, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "datasets/eval_datasets/nq/nq_ratio_0.525.tsv", "ARES_Prediction": 0.5308668117949733, "ARES_Confidence_Interval": [0.513, 0.549], "Number_of_Examples_in_Evaluation_Set": 5053, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.984, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "datasets/eval_datasets/nq/nq_ratio_0.55.tsv", "ARES_Prediction": 0.5550010366991499, "ARES_Confidence_Interval": [0.537, 0.573], "Number_of_Examples_in_Evaluation_Set": 4823, "Ground_Truth_Performance": 0.55, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.985, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "datasets/eval_datasets/nq/nq_ratio_0.575.tsv", "ARES_Prediction": 0.5781205289399522, "ARES_Confidence_Interval": [0.56, 0.596], "Number_of_Examples_in_Evaluation_Set": 4613, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.987, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "datasets/eval_datasets/nq/nq_ratio_0.6.tsv", "ARES_Prediction": 0.6023049083917665, "ARES_Confidence_Interval": [0.584, 0.621], "Number_of_Examples_in_Evaluation_Set": 4421, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.987, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "datasets/eval_datasets/nq/nq_ratio_0.625.tsv", "ARES_Prediction": 0.6266635249764373, "ARES_Confidence_Interval": [0.608, 0.645], "Number_of_Examples_in_Evaluation_Set": 4244, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.988, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "datasets/eval_datasets/nq/nq_ratio_0.65.tsv", "ARES_Prediction": 0.650132320509679, "ARES_Confidence_Interval": [0.632, 0.669], "Number_of_Examples_in_Evaluation_Set": 4081, "Ground_Truth_Performance": 0.65, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.989, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "datasets/eval_datasets/nq/nq_ratio_0.675.tsv", "ARES_Prediction": 0.6742239185750636, "ARES_Confidence_Interval": [0.656, 0.693], "Number_of_Examples_in_Evaluation_Set": 3930, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.99, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "datasets/eval_datasets/nq/nq_ratio_0.7.tsv", "ARES_Prediction": 0.6984432717678101, "ARES_Confidence_Interval": [0.68, 0.717], "Number_of_Examples_in_Evaluation_Set": 3790, "Ground_Truth_Performance": 0.7, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.991, "Annotated_Examples_used_for_PPI": 300}]]