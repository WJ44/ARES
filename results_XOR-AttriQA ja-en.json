[[{"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.5_ja_en.tsv", "ARES_Prediction": 0.21277777777777784, "ARES_Confidence_Interval": [0.096, 0.33], "Number_of_Examples_in_Evaluation_Set": 72, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.597, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.525_ja_en.tsv", "ARES_Prediction": 0.23957746478873243, "ARES_Confidence_Interval": [0.128, 0.352], "Number_of_Examples_in_Evaluation_Set": 71, "Ground_Truth_Performance": 0.521, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.592, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.55_ja_en.tsv", "ARES_Prediction": 0.1409859154929578, "ARES_Confidence_Interval": [0.012, 0.27], "Number_of_Examples_in_Evaluation_Set": 71, "Ground_Truth_Performance": 0.549, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.718, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.575_ja_en.tsv", "ARES_Prediction": 0.1550704225352113, "ARES_Confidence_Interval": [0.028, 0.282], "Number_of_Examples_in_Evaluation_Set": 71, "Ground_Truth_Performance": 0.577, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.732, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.6_ja_en.tsv", "ARES_Prediction": 0.22549295774647893, "ARES_Confidence_Interval": [0.111, 0.34], "Number_of_Examples_in_Evaluation_Set": 71, "Ground_Truth_Performance": 0.606, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.662, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.625_ja_en.tsv", "ARES_Prediction": 0.2544444444444445, "ARES_Confidence_Interval": [0.146, 0.363], "Number_of_Examples_in_Evaluation_Set": 72, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.653, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.65_ja_en.tsv", "ARES_Prediction": 0.19732394366197192, "ARES_Confidence_Interval": [0.077, 0.317], "Number_of_Examples_in_Evaluation_Set": 71, "Ground_Truth_Performance": 0.648, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.732, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.675_ja_en.tsv", "ARES_Prediction": 0.22549295774647893, "ARES_Confidence_Interval": [0.111, 0.34], "Number_of_Examples_in_Evaluation_Set": 71, "Ground_Truth_Performance": 0.676, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.732, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.7_ja_en.tsv", "ARES_Prediction": 0.22549295774647893, "ARES_Confidence_Interval": [0.111, 0.34], "Number_of_Examples_in_Evaluation_Set": 71, "Ground_Truth_Performance": 0.704, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.761, "Annotated_Examples_used_for_PPI": 100}]]