[[{"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.5_en_en.tsv", "ARES_Prediction": 0.2055555555555556, "ARES_Confidence_Interval": [0.073, 0.338], "Number_of_Examples_in_Evaluation_Set": 72, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.694, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.525_en_en.tsv", "ARES_Prediction": 0.2732394366197183, "ARES_Confidence_Interval": [0.15, 0.397], "Number_of_Examples_in_Evaluation_Set": 71, "Ground_Truth_Performance": 0.521, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.648, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.55_en_en.tsv", "ARES_Prediction": 0.23098591549295777, "ARES_Confidence_Interval": [0.101, 0.361], "Number_of_Examples_in_Evaluation_Set": 71, "Ground_Truth_Performance": 0.549, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.718, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.575_en_en.tsv", "ARES_Prediction": 0.17464788732394365, "ARES_Confidence_Interval": [0.038, 0.311], "Number_of_Examples_in_Evaluation_Set": 71, "Ground_Truth_Performance": 0.577, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.775, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.6_en_en.tsv", "ARES_Prediction": 0.3154929577464789, "ARES_Confidence_Interval": [0.2, 0.431], "Number_of_Examples_in_Evaluation_Set": 71, "Ground_Truth_Performance": 0.606, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.662, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.625_en_en.tsv", "ARES_Prediction": 0.28888888888888886, "ARES_Confidence_Interval": [0.169, 0.409], "Number_of_Examples_in_Evaluation_Set": 72, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.708, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.65_en_en.tsv", "ARES_Prediction": 0.2591549295774648, "ARES_Confidence_Interval": [0.134, 0.385], "Number_of_Examples_in_Evaluation_Set": 71, "Ground_Truth_Performance": 0.648, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.761, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.675_en_en.tsv", "ARES_Prediction": 0.2732394366197183, "ARES_Confidence_Interval": [0.15, 0.397], "Number_of_Examples_in_Evaluation_Set": 71, "Ground_Truth_Performance": 0.676, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.775, "Annotated_Examples_used_for_PPI": 100}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.7_en_en.tsv", "ARES_Prediction": 0.3154929577464789, "ARES_Confidence_Interval": [0.2, 0.431], "Number_of_Examples_in_Evaluation_Set": 71, "Ground_Truth_Performance": 0.704, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.761, "Annotated_Examples_used_for_PPI": 100}]]