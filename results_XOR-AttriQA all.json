[[{"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.5.tsv", "ARES_Prediction": 0.19847222222222216, "ARES_Confidence_Interval": [0.134, 0.263], "Number_of_Examples_in_Evaluation_Set": 288, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.622, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.525.tsv", "ARES_Prediction": 0.23197183098591545, "ARES_Confidence_Interval": [0.17, 0.294], "Number_of_Examples_in_Evaluation_Set": 284, "Ground_Truth_Performance": 0.521, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.609, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.55.tsv", "ARES_Prediction": 0.1791549295774647, "ARES_Confidence_Interval": [0.113, 0.246], "Number_of_Examples_in_Evaluation_Set": 284, "Ground_Truth_Performance": 0.549, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.69, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.575.tsv", "ARES_Prediction": 0.1369014084507042, "ARES_Confidence_Interval": [0.068, 0.206], "Number_of_Examples_in_Evaluation_Set": 284, "Ground_Truth_Performance": 0.577, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.754, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.6.tsv", "ARES_Prediction": 0.2671830985915492, "ARES_Confidence_Interval": [0.208, 0.326], "Number_of_Examples_in_Evaluation_Set": 284, "Ground_Truth_Performance": 0.606, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.644, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.625.tsv", "ARES_Prediction": 0.25749999999999995, "ARES_Confidence_Interval": [0.198, 0.317], "Number_of_Examples_in_Evaluation_Set": 288, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.674, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.65.tsv", "ARES_Prediction": 0.2108450704225352, "ARES_Confidence_Interval": [0.147, 0.275], "Number_of_Examples_in_Evaluation_Set": 284, "Ground_Truth_Performance": 0.648, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.743, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.675.tsv", "ARES_Prediction": 0.23197183098591545, "ARES_Confidence_Interval": [0.17, 0.294], "Number_of_Examples_in_Evaluation_Set": 284, "Ground_Truth_Performance": 0.676, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.75, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/attri_qa_test_ratio_0.7.tsv", "ARES_Prediction": 0.24605633802816895, "ARES_Confidence_Interval": [0.185, 0.307], "Number_of_Examples_in_Evaluation_Set": 284, "Ground_Truth_Performance": 0.704, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.764, "Annotated_Examples_used_for_PPI": 300}]]